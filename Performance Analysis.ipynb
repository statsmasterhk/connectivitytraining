{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480c21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Kranji-20180318-10 (1/92)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performanc analysis of Connectivity model\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util.result import import_subsequences_results\n",
    "from util.feature import triplet_feature_to_list\n",
    "from util.feature import pdist_np\n",
    "# Parameters\n",
    "csv_dir = \"G:/tim/Project/Connectivity_train_test/real_data/Kranji-2018\"\n",
    "feat_dir = \"D:/Bitbucket/triplettraining/feat/Kranji_test\"\n",
    "race_dir = \"D:/Bitbucket/triplettraining/feat/Kranji_test\"\n",
    "\n",
    "# csv_dir = \"G:/tim/Project/Connectivity_train_test/real_data/HVT-2018-2019_full_recall\"\n",
    "# feat_dir = \"G:/tim/Project/Connectivity_train_test/train_data/trip_feat/HVT-2018-2019_full_recall\"\n",
    "# race_dir = \"D:/Bitbucket/triplettraining/feat/HVT_test\"\n",
    "\n",
    "# Load Connectivity Model\n",
    "from model.conn import ConnNet\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"G:/tim/Project/Connectivity_train_test/res/Connectivity_batch_256_Kranji_2022-08-12-16-24-09/model_35.pkl\"\n",
    "#model_path = \"./conn.pth\"\n",
    "model = ConnNet().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "all_races = []\n",
    "\n",
    "race_dict = {}\n",
    "\n",
    "for race_path in os.listdir(race_dir):\n",
    "    racelb = os.path.splitext(race_path)[0]\n",
    "    race_dict[racelb] = {}\n",
    "\n",
    "for feat_path in os.listdir(feat_dir):\n",
    "    racelb = os.path.splitext(feat_path)[0]\n",
    "    full_feat_path = os.path.join(feat_dir,feat_path)\n",
    "    if racelb in race_dict:\n",
    "        race_dict[racelb][\"feat_path\"] = full_feat_path\n",
    "\n",
    "for csv_path in os.listdir(csv_dir):\n",
    "    racelb = os.path.splitext(csv_path)[0]\n",
    "    ext = os.path.splitext(csv_path)[1]\n",
    "    full_csv_path = os.path.join(csv_dir,csv_path)\n",
    "    #if ext == \".csv\":\n",
    "    if racelb in race_dict:\n",
    "        race_dict[racelb][\"csv_path\"] = full_csv_path\n",
    "    # Skip the not in feat dir races\n",
    "    \n",
    "# Use only races in the featue dir\n",
    "all_races = list(race_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To control frame different, Connectivity is trained with offset = 1,2\n",
    "t_diff = [1,2]\n",
    "\n",
    "# To find the optimized threshold or not\n",
    "THRESHOLD_OPTIMISE = True\n",
    "match_thres_list = [0.8]\n",
    "num_thres = len(match_thres_list)\n",
    "\n",
    "if THRESHOLD_OPTIMISE:\n",
    "    num_thres = 20\n",
    "    match_thres_list = np.linspace(0, 1, num_thres)\n",
    "\n",
    "precisions = [[] for _ in range(num_thres)]\n",
    "recalls = [[] for _ in range(num_thres)]\n",
    "best_f1_score = -1\n",
    "best_thres = 0\n",
    "best_precision = 0 \n",
    "best_recall = 0 \n",
    "best_match_thres_id = -1\n",
    "\n",
    "TPs = {}\n",
    "TP_dist = {}\n",
    "FPs = {}\n",
    "FP_dist = {}\n",
    "\n",
    "# Loop through each race\n",
    "for race_i in range(len(all_races)):\n",
    "    t_start = time.time()\n",
    "    each_race = all_races[race_i]\n",
    "    print(f\"Processing {each_race} ({race_i+1}/{len(all_races)})...\")\n",
    "    # Read CSV\n",
    "    tar_csv_path = race_dict[each_race][\"csv_path\"]\n",
    "    start_frm, end_frm, boxes_list = import_subsequences_results(tar_csv_path)\n",
    "    \n",
    "    # Read Feature\n",
    "    trip_feat_npy = np.load(race_dict[each_race][\"feat_path\"], \"r\", True)\n",
    "    trip_feat_list = triplet_feature_to_list(trip_feat_npy, boxes_list)\n",
    "    \n",
    "    # For Peformance analysis of each race\n",
    "    TPs_all = [[] for _ in range(num_thres)]\n",
    "    TP_dist_all = [[] for _ in range(num_thres)]\n",
    "    FPs_all = [[] for _ in range(num_thres)]\n",
    "    FP_dist_all = [[] for _ in range(num_thres)]\n",
    "    \n",
    "    # Loop through each frame offset \n",
    "    for t_index in range(len(t_diff)):\n",
    "        offset = t_diff[t_index]\n",
    "        # For storing num of TPs and FPs only\n",
    "        TPs_stats = [0]*num_thres\n",
    "        FPs_stats = [0]*num_thres\n",
    "        total_matchable = 0\n",
    "        # Do performance analysis\n",
    "        for frm_id in range(len(trip_feat_list)):\n",
    "            t0 = frm_id\n",
    "            t1 = frm_id + offset\n",
    "            if t1 >= len(trip_feat_list):\n",
    "                continue\n",
    "            if len(trip_feat_list[t0]) == 0 or len(trip_feat_list[t1]) == 0: \n",
    "                continue\n",
    "            \n",
    "            # Construct input for connectivity model\n",
    "            t0_boxes = boxes_list[t0]\n",
    "            t1_boxes = boxes_list[t1]        \n",
    "            t0_ids = []\n",
    "            t1_ids = []\n",
    "            inputs = []\n",
    "            for box_id_0 in range(len(t0_boxes)):\n",
    "                jk_id_0 = t0_boxes[box_id_0][-1]\n",
    "                if jk_id_0 not in t0_ids:\n",
    "                    t0_ids.append(jk_id_0)\n",
    "                for box_id_1 in range(len(t1_boxes)):\n",
    "                    jk_id_1 = t1_boxes[box_id_1][-1]\n",
    "                    if jk_id_1 not in t1_ids:\n",
    "                        t1_ids.append(jk_id_1)\n",
    "\n",
    "                    cap_0_feat = trip_feat_list[t0][box_id_0]\n",
    "                    cap_1_feat = trip_feat_list[t1][box_id_1]\n",
    "                    cap_0 = t0_boxes[box_id_0]\n",
    "                    cap_1 = t1_boxes[box_id_1]\n",
    "                    cap_0_cx = int((cap_0[1] + cap_0[3]) / 2)\n",
    "                    cap_0_cy = int((cap_0[0] + cap_0[2]) / 2)\n",
    "                    cap_1_cx = int((cap_1[1] + cap_1[3]) / 2)\n",
    "                    cap_1_cy = int((cap_1[0] + cap_1[2]) / 2)\n",
    "                    cap_1_w = int((cap_0[1] + cap_0[3]) / 2)\n",
    "                    cap_1_h = int((cap_0[0] + cap_0[2]) / 2)\n",
    "                    # Normalise\n",
    "                    feat_diff = np.sum((cap_0_feat - cap_1_feat) ** 2) ** 0.5\n",
    "                    dx = abs(cap_0_cx - cap_1_cx) / (math.sqrt(cap_1_w * cap_1_h) * 100)\n",
    "                    dy = abs(cap_0_cy - cap_1_cy) / (math.sqrt(cap_1_w * cap_1_h) * 50)\n",
    "                    norm_t = offset / 2\n",
    "                    tensor_in = torch.tensor([feat_diff,dx,dy,norm_t]).float()\n",
    "                    inputs.append(tensor_in)\n",
    "            inputs = torch.stack(inputs).to(device)\n",
    "            # Run inputs with connectivity model, and reshape it into num_cap_t0 * num_cap_t1 matrix\n",
    "            prob_mtx = []\n",
    "            with torch.no_grad():\n",
    "                prob_mtx = model(inputs).detach().cpu().numpy()[:,1]\n",
    "                prob_mtx = prob_mtx.reshape(len(t0_ids),len(t1_ids))\n",
    "            # Calculate matchable ids number (exists in both t0 and t1) and all pairs\n",
    "            matchable_ids = set(t0_ids) & set(t1_ids)\n",
    "            num_match = len(matchable_ids)\n",
    "            total_matchable += num_match\n",
    "            num_pairs = len(t0_ids) * len(t1_ids)\n",
    "            \n",
    "            for match_thres_id in range(num_thres):\n",
    "                match_thres = match_thres_list[match_thres_id]\n",
    "                matchable_mtx = np.any(prob_mtx > match_thres,axis = 1)\n",
    "                num_candidate = sum(matchable_mtx)\n",
    "                max_prob_ids = np.argmax(prob_mtx,axis = 1)\n",
    "\n",
    "                for x in range(len(max_prob_ids)):\n",
    "                    valid = matchable_mtx[x]\n",
    "                    if not valid:\n",
    "                        continue\n",
    "                    id_in_t0 = x\n",
    "                    id_in_t1 = max_prob_ids[x]\n",
    "                    tar_name_t0 = t0_ids[id_in_t0]\n",
    "                    tar_name_t1 = t1_ids[id_in_t1]\n",
    "                    prob = prob_mtx[x][id_in_t1]\n",
    "                    if tar_name_t0 == tar_name_t1:\n",
    "                        #print(TPs_all[match_thres_id] + [f\"frm_{t0}_{tar_name_t0}_frm_{t1}_{tar_name_t1}\"])\n",
    "                        TPs_all[match_thres_id].append(f\"frm_{t0}_{tar_name_t0}_frm_{t1}_{tar_name_t1}\")\n",
    "                        #print(len(TPs_all[match_thres_id]),TPs_stats[match_thres_id])\n",
    "                        TP_dist_all[match_thres_id].append(prob)\n",
    "                        TPs_stats[match_thres_id]+=1\n",
    "                    else:\n",
    "                        FPs_all[match_thres_id].append(f\"frm_{t0}_{tar_name_t0}_frm_{t1}_{tar_name_t1}\")\n",
    "                        FP_dist_all[match_thres_id].append(prob)\n",
    "                        FPs_stats[match_thres_id]+=1\n",
    "        # Calculate the precisions and recalls for each threshold\n",
    "        for match_thres_id in range(num_thres):\n",
    "            num_TP = TPs_stats[match_thres_id]\n",
    "            num_FP = FPs_stats[match_thres_id]\n",
    "            total_matches = num_TP + num_FP\n",
    "            precision = 0\n",
    "            recall = num_TP / total_matchable\n",
    "            if (total_matches>0):\n",
    "                precision = num_TP / total_matches\n",
    "\n",
    "            precisions[match_thres_id].append(precision)\n",
    "            recalls[match_thres_id].append(recall)\n",
    "    \n",
    "    for match_thres_id in range(num_thres):\n",
    "        match_thres = match_thres_list[match_thres_id]\n",
    "        #print(f\"Match Threshold:{match_thres}\")\n",
    "        avg_precision = sum(precisions[match_thres_id])/len(precisions[match_thres_id])\n",
    "        avg_recall = sum(recalls[match_thres_id])/len(recalls[match_thres_id])\n",
    "        avg_f1 = 0\n",
    "        if (avg_precision+avg_recall)>0:\n",
    "            avg_f1 = 2*avg_precision*avg_recall/(avg_precision+avg_recall)\n",
    "        #print(match_thres,avg_f1)\n",
    "        if avg_f1 > best_f1_score or best_match_thres_id == match_thres_id:\n",
    "            best_f1_score = avg_f1\n",
    "            best_match_thres_id = match_thres_id\n",
    "            best_thres = match_thres\n",
    "            best_precision = avg_precision\n",
    "            best_recall = avg_recall\n",
    "            \n",
    "            TPs[each_race] = TPs_all[best_match_thres_id]\n",
    "            TP_dist[each_race] = TP_dist_all[best_match_thres_id]\n",
    "            FPs[each_race] = FPs_all[best_match_thres_id]\n",
    "            FP_dist[each_race] = FP_dist_all[best_match_thres_id]\n",
    "            \n",
    "    t_end = time.time()\n",
    "    print(f\"Time_taken: {t_end-t_start}, best_match_thres: {best_thres}, best_f1_score: {best_f1_score}, with avg_precision: {best_precision}, avg_recall: {best_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024026a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_match_thres: 0.0, with avg_precision: 0.966143094879151, avg_recall: 0.9983455343687493\n",
      "Best_match_thres: 0.05263157894736842, with avg_precision: 0.993944932158197, avg_recall: 0.9966537349964872\n",
      "Best_match_thres: 0.10526315789473684, with avg_precision: 0.9950476144185382, avg_recall: 0.9951649556036265\n",
      "Best_match_thres: 0.15789473684210525, with avg_precision: 0.995592103160094, avg_recall: 0.993933754087289\n",
      "Best_match_thres: 0.21052631578947367, with avg_precision: 0.9959649477901585, avg_recall: 0.992664240010454\n",
      "Best_match_thres: 0.2631578947368421, with avg_precision: 0.9962255493121445, avg_recall: 0.9913314600784027\n",
      "Best_match_thres: 0.3157894736842105, with avg_precision: 0.9964291955036053, avg_recall: 0.9899488566943169\n",
      "Best_match_thres: 0.3684210526315789, with avg_precision: 0.9966008327694706, avg_recall: 0.9884295546384415\n",
      "Best_match_thres: 0.42105263157894735, with avg_precision: 0.9967597235069553, avg_recall: 0.986859837815178\n",
      "Best_match_thres: 0.47368421052631576, with avg_precision: 0.9969318509273017, avg_recall: 0.9850711964200092\n",
      "Best_match_thres: 0.5263157894736842, with avg_precision: 0.9970817705822412, avg_recall: 0.9830751662059405\n",
      "Best_match_thres: 0.5789473684210527, with avg_precision: 0.9972253634983058, avg_recall: 0.9807914756650485\n",
      "Best_match_thres: 0.631578947368421, with avg_precision: 0.9973410269713484, avg_recall: 0.9779384038853524\n",
      "Best_match_thres: 0.6842105263157894, with avg_precision: 0.997506785405881, avg_recall: 0.97456599979936\n",
      "Best_match_thres: 0.7368421052631579, with avg_precision: 0.9976339050357815, avg_recall: 0.9705738776047959\n",
      "Best_match_thres: 0.7894736842105263, with avg_precision: 0.9977860868038801, avg_recall: 0.9653241144739576\n",
      "Best_match_thres: 0.8421052631578947, with avg_precision: 0.9979474112934161, avg_recall: 0.9580242727923547\n",
      "Best_match_thres: 0.894736842105263, with avg_precision: 0.9981636672145366, avg_recall: 0.9453390183183544\n",
      "Best_match_thres: 0.9473684210526315, with avg_precision: 0.9984857661150074, avg_recall: 0.9217716260605827\n",
      "Best_match_thres: 1.0, with avg_precision: 0.0, avg_recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "tar_race = \"Kranji-20180615-10\"\n",
    "len(FPs[tar_race])\n",
    "#print(FP_dist[tar_race])\n",
    "\n",
    "for i in range(num_thres):\n",
    "    match_thres = match_thres_list[i]\n",
    "    avg_precision = sum(precisions[i])/len(precisions[i])\n",
    "    avg_recall = sum(recalls[i])/len(recalls[i])\n",
    "    print(f\"Best_match_thres: {match_thres}, with avg_precision: {avg_precision}, avg_recall: {avg_recall}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
